{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Data from the Web\n",
    "\n",
    "## Screen Scraping, Regular Expressions, requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get inital page for cast list of F.R.I.E.N.D.S\n",
    "base_url = 'https://www.imdb.com'\n",
    "friends_url = f'{base_url}/title/tt0108778/fullcredits?ref_=tt_cl_sm#cast'\n",
    "\n",
    "res = requests.get(friends_url)\n",
    "dom = BeautifulSoup(res.text)\n",
    "\n",
    "# find anchor tag nested underneath td with class primary_photo\n",
    "# (which in turn, is nested underneath a table with class,\n",
    "# .cast_list containing a tr)\n",
    "selector = '.cast_list tr td.primary_photo a'\n",
    "links = dom.select(selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "# just the first 15 actors / actresses for now...\n",
    "for link in links[:15]:\n",
    "    link = f'{base_url}/{link[\"href\"]}'\n",
    "    # print(link)\n",
    "    res = requests.get(link)\n",
    "    dom = BeautifulSoup(res.text)\n",
    "    \n",
    "    # get the actor/actress name from title\n",
    "    name = dom.select('title')[0].get_text().replace(' - IMDb', '')\n",
    "    \n",
    "    # find the part of the page that has NNN credits\n",
    "    div = dom.select('#filmo-head-actress, #filmo-head-actor')\n",
    "    \n",
    "    # match (NNN credits), but make sure to capture digits\n",
    "    regex = '\\((\\d+) credits\\)'\n",
    "    m = re.search(regex, div[0].get_text())\n",
    "    num = m.group(1)\n",
    "    \n",
    "    try:\n",
    "        d[name] = int(num)\n",
    "    except ValueError:\n",
    "        d[name] = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elliott Gould          188\n",
       "Paul Rudd              120\n",
       "Jessica Hecht           95\n",
       "Christina Pickles       91\n",
       "Lisa Kudrow             83\n",
       "Maggie Wheeler          72\n",
       "Courteney Cox           67\n",
       "Jennifer Aniston        64\n",
       "Matthew Perry           58\n",
       "David Schwimmer         56\n",
       "Jane Sibbett            52\n",
       "Helen Baxendale         46\n",
       "Matt LeBlanc            32\n",
       "June Gable              22\n",
       "James Michael Tyler     17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(d).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing json, Pagination, API Usage\n",
    "\n",
    "Assuming API described is paginated with 20 per page:\n",
    "\n",
    "* `info` key has meta information about response\n",
    "    * ... meta info includes `next` for next url\n",
    "* `results` has actual data\n",
    "* note that api base url must be filled in manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import urllib                             # make http requests\n",
    "from pandas.io.json import json_normalize # flatten nested json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_gen(start_url):\n",
    "    \"\"\"\n",
    "    generator for retrieving paginated data from api \n",
    "    \n",
    "    :param start_url: api end point\n",
    "    :yield parsed json data from api\n",
    "    \"\"\"\n",
    "    next_url = start_url\n",
    "    while next_url is not None:\n",
    "        # print('retrieving', next_url)\n",
    "        \n",
    "        # GET url and parse resulting json\n",
    "        res = urllib.request.urlopen(next_url)\n",
    "        s = res.read()\n",
    "        json_obj = json.loads(s)\n",
    "        \n",
    "        # based on api documentation, payload is in\n",
    "        # results key\n",
    "        data = json_obj.get('results')\n",
    "        \n",
    "        # next is in the meta information under\n",
    "        # info and next\n",
    "        next_url = json_obj['info'].get('next')\n",
    "        next_url = next_url if next_url and 'http' in next_url else None \n",
    "        \n",
    "        yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in api url with trailing slash\n",
    "base = 'base url with trailing slash goes here'\n",
    "url = f'{base}character'\n",
    "\n",
    "# start with empty DataFrame as accumulator\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# loop over generator\n",
    "for data in api_gen(url):\n",
    "    # create a DataFrame with json_normalize\n",
    "    # with each \"returned\" value (loop variable, data)\n",
    "    # ...and add it to accumulator\n",
    "    df = df.append(json_normalize(data))\n",
    "    \n",
    "# fix row numbers\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
